}")
ggdag(tidy_dagitty(g))
source("../miscellaneous files/fit_gam.R")
gam_fits <- fit_gam(dag = g, data = GSSvocab)
source("../miscellaneous files/sim_mixed_dag_gam_fits.R")
a <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = 123)
source("../miscellaneous files/fit_gam.R")
gam_fits <- fit_gam(dag = g, data = GSSvocab)
source("../miscellaneous files/sim_mixed_dag_gam_fits.R")
a <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = 123)
View(a)
source("../miscellaneous files/fit_gam.R")
gam_fits <- fit_gam(dag = g, data = GSSvocab)
source("../miscellaneous files/sim_mixed_dag_gam_fits.R")
a <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = 123)
head(a)
a <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = 123)
head(a)
View(fit_gam)
a <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
p1 <- GSSvocab %>% ggplot(aes(educGroup, vocab)) + geom_boxplot()
p1
sim_data <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
p2 <- sim_data %>% ggplot(aes(educGroup, vocab)) + geom_boxplot() + ggtitle("Simulated data")
p2
grid.arrange(p1, p2, nrow = 1)
grid.arrange(p1, p2, nrow = 1)
p2 <- sim_data %>% ggplot(aes(educGroup, vocab)) + geom_boxplot() + ggtitle("Simulated data") + coord_cartesian(ylim = c(0,10))
grid.arrange(p1, p2, nrow = 1)
p1 <- GSSvocab %>% ggplot(aes(educGroup, vocab)) + geom_boxplot() + ggtitle("Original data")
p2 <- sim_data %>% ggplot(aes(educGroup, vocab)) + geom_boxplot() + ggtitle("Simulated data") + coord_cartesian(ylim = c(0,10))
grid.arrange(p1, p2, nrow = 1)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(educGroup, vocab)) + geom_boxplot() + facet_wrap(~data)
names(sim_data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(age, vocab)) + geom_point() + facet_wrap(~data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(age, vocab)) + geom_point() + facet_wrap(~data) + stat_smooth()
plot(GSSvocab$educ, GSSvocab$vocab)
GSSvocab %>% ggplot(aes(educ, vocab)) + geom_point() + stat_smooth()
GSSvocab %>% ggplot(aes(educ, vocab)) + geom_point(alpha = 0.1) + stat_smooth()
GSSvocab %>% ggplot(aes(educ, vocab)) + geom_point(alpha = 0.05) + stat_smooth()
str(GSSvocab)
g <- dagitty("dag {
nativeBorn -> educ
nativeBorn -> vocab
educ -> vocab
gender -> educ
age -> vocab
}")
ggdag(tidy_dagitty(g))
g <- dagitty("dag {
nativeBorn -> educ
nativeBorn -> vocab
educ -> vocab
gender -> educ
ageGroup -> vocab
}")
ggdag(tidy_dagitty(g))
source("../miscellaneous files/fit_gam.R")
gam_fits <- fit_gam(dag = g, data = GSSvocab)
source("../miscellaneous files/sim_mixed_dag_gam_fits.R")
sim_data <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
str(sim_data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(ageGroup, vocab)) + geom_boxplot() + facet_wrap(~data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(gender, vocab)) + geom_boxplot() + facet_wrap(~data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(nativeBorn, vocab)) + geom_boxplot() + facet_wrap(~data)
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(educ, vocab)) + geom_point(alpha = 0.02) + facet_wrap(~data) + stat_smooth()
bind_rows(GSSvocab %>% mutate(data = "Origial"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(educ, vocab)) + geom_point(alpha = 0.02) + facet_wrap(~data) + stat_smooth()
str(sim_data)
sim_data %>% group_by(ageGroup, gender) %>% summarise(freq = n()/nrow(.))
GSSvocab %>% group_by(ageGroup, gender) %>% summarise(freq = n()/nrow(.))
sim_data %>% group_by(ageGroup, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
GSSvocab %>% group_by(ageGroup, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
names(sim_data)
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
sim_data <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
sim_data <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq)
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table()
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Simulated data")
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Original data")
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Original data")
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Original data")
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Simulated data")
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Simulated data")
?dagify
?tidy_dagitty
ggdag(tidy_dagitty(g, seed = 1))
ggdag(tidy_dagitty(g, seed = 1))
ggdag(tidy_dagitty(g, seed = 1))
ggdag(tidy_dagitty(g, seed = 1))
ggdag(tidy_dagitty(g, seed = 1))
ggdag(tidy_dagitty(g, seed = 2))
ggdag(tidy_dagitty(g, seed = 3))
ggdag(tidy_dagitty(g, seed = 3))
ggdag(tidy_dagitty(g, seed = 3))
ggdag(tidy_dagitty(g, seed = 3), node_size = 30)
ggdag(tidy_dagitty(g, seed = 3), node_size = 25)
g <- dagitty("dag {
ageGroup [pos=\"0,0\"]
vocab [pos=\"1,-1\"]
nativeBorn [pos=\"2,-2\"]
educ [pos=\"3,-1\"]
gender [pos=\"4,0\"]
nativeBorn -> educ
nativeBorn -> vocab
educ -> vocab
gender -> educ
ageGroup -> vocab
}")
tidy_dag <- tidy_dagitty(g)
ggdag(tidy_dag)
ggdag(tidy_dag, node_size = 25)
ggdag(tidy_dag, node_size = 25)
ggdag(tidy_dag, node_size = 28)
tidy_dag <- tidy_dagitty(g)
tidy_dag$data$xend[1] <- 0.04; tidy_dag$data$yend[1] <- 0.04
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data
tidy_dag <- tidy_dagitty(g)
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[1] <- 0.96; tidy_dag$data$yend[1] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[1] <- 0.95; tidy_dag$data$yend[1] <- -0.95
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[2] <- 1.05; tidy_dag$data$yend[1] <- -0.95
tidy_dag$data$xend[1] <- 0.95; tidy_dag$data$yend[1] <- -0.95
tidy_dag$data$xend[2] <- 1.05
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[2] <- 1.06
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[2] <- 1.08
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[3] <- 2.05; tidy_dag$data$yend[3] <- 0.05
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[3] <- 3.05; tidy_dag$data$yend[3] <- -1.05
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[1] <- 0.95; tidy_dag$data$yend[1] <- -0.96
tidy_dag$data$xend[2] <- 1.08
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[1] <- 0.94; tidy_dag$data$yend[1] <- -0.96
tidy_dag$data$xend[2] <- 1.08
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[1] <- 0.92; tidy_dag$data$yend[1] <- -0.96
tidy_dag$data$xend[2] <- 1.08
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data
tidy_dag$data$xend[4] <- 2.92; tidy_dag$data$yend[4] <- -1.04
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
tidy_dag$data$xend[5] <- 1.07; tidy_dag$data$yend[5] <- -1.04
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
library(anytime)
install.packages("anytime")
rm(list=ls())
library(anytime)
library(zoo)
library(glmnet)
library(e1071)
library(knitr)
rm(list=ls())
library(anytime)
library(zoo)
library(glmnet)
library(e1071)
library(knitr)
setwd("~/Downloads/")
train = read.csv('train_data.csv')
train = train[,-c(1,2,3,5,7,11)]
train_x = train[,-c(7)]
test = read.csv('test_data.csv')
test = test[,-c(1,2,3,5,7,11)]
train_ind = c(1:nrow(train))
test_start = nrow(train)+1
test_end = test_start+nrow(test)
test_ind = c(test_start:test_end)
features = rbind(train_x,test)
features$Loaned.From = as.character(features$Loaned.From)
features$Loaned.From[is.na(features$Loaned.From)] = 'No Loan'
Categorical = c(2,5,8,12,13,14,15,16,18)
Ordinal = c(9,10,11)
features_categorical = features[,Categorical]
features_ordinal = features[,Ordinal]
features_numeric = features[,-c(Ordinal,Categorical)]
for (feature in c(Ordinal,Categorical)){
features[,feature] = addNA(features[,feature])
}
values =c()
release_clauses = c()
Values = substr(as.character(features$Value),5,10)
RC = substr(as.character(features$Release.Clause),5,10)
for (i in c(1:length(Values))){
value = Values[i]
rc = RC[i]
if (!is.na(value)){
value_scale = substr(value, nchar(value), nchar(value))
value_numeric = as.numeric(substr(value, 1, nchar(value)-1))
if (value_scale=='M'){
value_numeric = value_numeric*1000}}
if (!is.na(rc)){
rc_scale = substr(rc, nchar(rc), nchar(rc))
rc_numeric = as.numeric(substr(rc, 1, nchar(rc)-1))
if (rc_scale=='M' ){
rc_numeric = rc_numeric*1000}}
values = c(value_numeric)
release_clauses = c(release_clauses,rc_numeric)
}
features$Value = values
features$Release.Clause = release_clauses
joined = as.character(features$Joined)
month = substr(joined,1,3)
day = substr(joined,4,7)
year = substr(joined,8,12)
time_diff = c()
for (i in c(1:length(year))){
if (!is.na(day[i])){
y = gsub("[^0-9\\.]", "", year[i])
d = gsub("[^0-9\\.]", "", day[i])
m = tolower(month[i])
if (nchar(d)==1){
d = paste('0',d,sep = '')}
date = substr(anytime(paste(d,m,y,sep='')),1,10)
date = gsub("-", ".", date)
now = substr(Sys.Date(),1,10)
now = gsub("-", ".", now)
time_diff_i = (as.yearmon(strptime(now, format = "%Y.%m.%d"))-
as.yearmon(strptime(date, format = "%Y.%m.%d")))*12
time_diff = c(time_diff,time_diff_i)
}
if (is.na(day[i])){
time_diff = c(time_diff,NA)
}}
features$Joined = time_diff
naive_predictors = c(1,2,3,4,5)
na_ind = is.na(features$Joined)
x = features[!na_ind,naive_predictors]
y = as.factor(features$Joined[!na_ind])
Naive_Bayes_Model=naiveBayes(x=x ,y=y)
x_new = features[na_ind,naive_predictors]
prediction <- round(as.numeric(as.character(predict(Naive_Bayes_Model,x_new))))
features$Joined[na_ind] = prediction
contact = as.character(features$Contract.Valid.Until)
years_on_contact = c()
for (i in c(1:length(contact))){
c_i = contact[i]
if (!is.na(c_i)){
if (nchar(c_i)==4){
years_on_contact = c(years_on_contact,as.numeric(c_i)-2018)
}
if (nchar(c_i)>4){
yr = strsplit(c_i,' ')[[1]][length(strsplit(c_i,' ')[[1]])]
years_on_contact = c(years_on_contact,as.numeric(yr)-2018)
}}
if (is.na(c_i)){
years_on_contact = c(years_on_contact,0)
}
}
features$Contract.Valid.Until = as.numeric(years_on_contact)
h = as.character(features$Height)
w =  as.character(features$Weight)
height = c()
weight = c()
for (i in c(1:length(w))){
h_i=h[i]
w_i=w[i]
if (!is.na(h_i)){
h_i = as.numeric(gsub("'", ".", h_i))}
if (!is.na(w_i)){
w_i =as.numeric(gsub("[^0-9\\.]", "", w_i))}
height = c(height,h_i)
weight = c(weight,w_i)
}
features$Weight = as.numeric(weight)
features$Height = as.numeric(height)
for (i in c(22:54)){
f_i = as.character(features[,i])
f = c()
for (j in c(1:length(f_i))){
f_j = f_i[j]
if (!is.na(f_j)){
if ('+' %in% strsplit(f_j,split = '')[[1]]){
f = c(f,as.numeric(strsplit(f_j,'[+]')[[1]][1])+as.numeric(strsplit(f_j,'[+]')[[1]][2]))}
else{
f = c(f,as.numeric(f_j))
}}
if(is.na(f_j)){
f = c(f,f_j)
}
}
features[,i] = as.numeric(f)
}
features$Position[is.na(features$RWB)] = 'GK' #We need to fill a bit of missing gk
y = train$Wage
train_matrix = features[train_ind,]
test = features[test_ind,]
no_data_test = !is.na(test$Height)
test = test[no_data_test,]
no_data_train = !is.na(train_matrix$Height)
train_matrix = train_matrix[no_data_train,] #Rows without any data
y = y[no_data_train]
x_gk = train_matrix[train_matrix$Position=='GK',-c(22:47)]
y_gk = y[train_matrix$Position=='GK']
y_outfield = y[train_matrix$Position!='GK']
x_outfield = train_matrix[train_matrix$Position!='GK',]
test_outfiled = test[test$Position!='GK',]
test_gk = test[test$Position=='GK',-c(22:47)]
train_ind_outfield = sample(c(1:nrow(x_outfield)),floor(0.7*nrow(x_outfield)))
train_ind_gk = sample(c(1:nrow(x_gk)),floor(0.7*nrow(x_gk)))
train_outfield =x_outfield[train_ind_outfield,]
train_gk = x_gk[train_ind_gk,]
validation_gk = x_gk[-train_ind_gk,]
y_gk_validation = y_gk[-train_ind_gk]
y_gk_train = y_gk[train_ind_gk]
y_outfield_train = y_outfield[train_ind_outfield]
validation_outfield = x_outfield[-train_ind_outfield,]
y_outfield_validation = y_outfield[-train_ind_outfield]
x_cat = train_outfield[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,train_outfield[,-c(Categorical,Ordinal)]))
fit_outfield_lasso=cv.glmnet(x,y_outfield_train,alpha =1,intercept=FALSE , nfolds=7)
fit_outfield_ridge=cv.glmnet(x,y_outfield_train,alpha =0,intercept=FALSE , nfolds=7)
fit_outfield_en=cv.glmnet(x,y_outfield_train,alpha =0.5,intercept=FALSE , nfolds=7)
fit_outfield_regression = lm(y_outfield_train ~ x -1)
x_cat = train_gk[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,train_gk[,-c(Categorical,Ordinal)]))
fit_gk_lasso=cv.glmnet(x,y_gk_train,alpha =1,intercept=FALSE , nfolds=7)
fit_gk_ridge=cv.glmnet(x,y_gk_train,alpha =0,intercept=FALSE , nfolds=7)
fit_gk_en=cv.glmnet(x,y_gk_train,alpha =0.5,intercept=FALSE , nfolds=7)
fit_gk_regression = lm(y_gk_train~x -1)
x_cat = validation_outfield[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,validation_outfield[,-c(Categorical,Ordinal)]))
outfield_lasso_pred <-predict(fit_outfield_lasso, x,
s = "lambda.min")
outfield_ridge_pred <-predict(fit_outfield_ridge, x,
s = "lambda.min")
outfield_en_pred <-predict(fit_outfield_en, x,
s = "lambda.min")
outfield_regression_pred = predict(fit_outfield_regression,data.frame(x))
x_cat = validation_gk[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,validation_gk[,-c(Categorical,Ordinal)]))
gk_lasso_pred <-predict(fit_gk_lasso, x,
s = "lambda.min")
gk_ridge_pred <-predict(fit_gk_ridge, x,
s = "lambda.min")
gk_en_pred <-predict(fit_gk_en, x,
s = "lambda.min")
gk_regression_pred = predict(fit_gk_regression,data.frame(x))
mse_outfield_lasso = mean((y_outfield_validation-outfield_lasso_pred)^2)
mse_outfield_ridge = mean((y_outfield_validation-outfield_ridge_pred)^2)
mse_outfield_en = mean((y_outfield_validation-outfield_en_pred)^2)
mse_outfield_regression = mean((y_outfield_validation-outfield_regression_pred)^2)
error_outfield = data.frame(matrix(c(mse_outfield_lasso,mse_outfield_ridge,mse_outfield_en,mse_outfield_regression)))
rownames(error_outfield) = c('lasso','ridge','elastic net','regression')
colnames(error_outfield) = 'MSE'
kable(error_outfield)
mse_gk_lasso = mean((y_gk_validation-gk_lasso_pred)^2)
mse_gk_ridge = mean((y_gk_validation-gk_ridge_pred)^2)
mse_gk_en = mean((y_gk_validation-gk_en_pred)^2)
mse_gk_regression = mean((y_gk_validation-gk_regression_pred  )^2)
error_gk = data.frame(matrix(c(mse_gk_lasso,mse_gk_ridge,mse_outfield_en,mse_gk_regression)))
rownames(error_gk) = c('lasso','ridge','elastic net','regression')
colnames(error_gk) = 'MSE'
kable(error_gk)
x_cat_train = train_outfield[,c(Categorical,Ordinal)]
x_cat_val = validation_outfield[,c(Categorical,Ordinal)]
x_train <- model.matrix( ~ . -1,x_cat_train )
x_val = model.matrix( ~ . -1,x_cat_val )
x = rbind(x_train,x_val)
x_num = rbind(train_outfield[,-c(Categorical,Ordinal)],validation_outfield[,-c(Categorical,Ordinal)])
x = as.matrix(cbind(x,x_num))
fit_outfield_regression = lm(y_outfield ~ x -1)
x_cat_train = train_gk[,c(Categorical,Ordinal)]
x_cat_val = validation_gk[,c(Categorical,Ordinal)]
x_train <- model.matrix( ~ . -1,x_cat_train )
x_val = model.matrix( ~ . -1,x_cat_val )
x = rbind(x_train,x_val)
x_num = rbind(train_gk[,-c(Categorical,Ordinal)],validation_gk[,-c(Categorical,Ordinal)])
x = as.matrix(cbind(x,x_num))
fit_gk_lasso=cv.glmnet(x,y_gk,alpha =1,intercept=FALSE , nfolds=7)
x_cat = test_outfiled[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,test_outfiled[,-c(Categorical,Ordinal)]))
predictions = c(mean(y))*nrow(test)
predictions[test$Position!='GK'] = predict(fit_outfield_regression,data.frame(x))
x_cat = test_gk[,c(Categorical,Ordinal)]
x <- model.matrix( ~ . -1,x_cat )
x = as.matrix(cbind(x,test_gk[,-c(Categorical,Ordinal)]))
predictions[test$Position=='GK'] = predict(fit_gk_lasso, x,s = "lambda.min")
head(test)
test = read.csv('test_data.csv')
test_end
test_start
lenght(test_ind)
length(test_ind)
tidy_dag <- tidy_dagitty(g)
knitr::opts_chunk$set(echo = F, warning = F, message = F, cache = F)
set.seed(1)
options(scipen = 999)
packages <- c(
"tidyverse", # best thing that ever happend to me
"pander", # table rendering
"dagitty", # Create DAGs
"ggdag", # ggplot DAGs
"gridExtra"
)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(char = packages)
g <- dagitty("dag {
sales [pos=\"0,0\"]
mkt [pos=\"2,0\"]
comp [pos=\"1,1\"]
visits [pos=\"1,0\"]
visits -> sales
mkt -> visits
comp -> mkt
comp -> sales
}")
ggdag(tidy_dagitty(g)) + theme_dag_blank()
source("../miscellaneous files/sim_mixed_dag.R")
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -2)),
mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(comp, sales)) + geom_point() + stat_smooth(method = "lm")
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -2), sinr = 5),
mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(comp, sales)) + geom_point() + stat_smooth(method = "lm")
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -2), link = "cosin", sinr = 3),
mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(comp, sales)) + geom_point() + stat_smooth()
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -2), link = "quadratic", sinr = 3),
mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(comp, sales)) + geom_point() + stat_smooth()
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -1), link = "exp", sinr = 2),
mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(comp, sales)) + geom_point() + stat_smooth()
sim_data <- sim_mixed_dag(dag = g, f.args = list(sales = list(betas = list(comp = -2),
link = "quadratic", sinr = 3, levels = 3, labels = c("low", "medium", "high")), mkt = list(betas = list(comp = 0))))
sim_data %>% ggplot(aes(sales, comp)) + geom_boxplot() + stat_smooth()
f.args_partial = list(sales = list(betas = list(comp = -2),
link = "quadratic", sinr = 3, levels = 3,
labels = c("low", "medium", "high")), mkt = list(betas = list(comp = 0)))
print(f.args_partial)
source("../miscellaneous files/gen_model_param.R")
f.args_full <- gen_model_param(dag = g, f.args = f.args_partial)
print(f.args_full)
source("../miscellaneous files/get_ate.R")
f.args <- gen_model_param(dag = g, f.args = list(sales = list(betas = list(visits = 0.3, comp = -0.9)),
visits = list(betas = list(mkt = 0.5)),
mkt = list(betas = list(comp = 0.6))))
a <- get_ate(dag = g, f.args = f.args, treatment = "mkt", treatment_vals = seq(-2, 2), exposure = "sales")
pandoc.table(a)
f.args <- gen_model_param(dag = g, f.args = list(visits = list(betas = list(mkt = c(0.5, 1.2)), levels = 1),
sales = list(betas = list(visits = 1.5, comp = -4), link = "quadratic"),
mkt = list(betas = list(comp = 2), levels = 3, labels = c("low", "medium", "high"),
link = "exp", sinr = 8)))
treat_vals <- factor(c("low", "medium", "high"), levels = c("low", "medium", "high"))
a <- get_ate(dag = g, f.args = f.args, treatment = "mkt", treatment_vals = treat_vals, exposure = "sales")
pandoc.table(a)
sim_data <- sim_mixed_dag(dag = g, f.args, N = 10000)
sim_data %>% ggplot(aes(mkt, sales)) + geom_boxplot() + stat_smooth() + coord_cartesian(ylim = c(-50, 50))
f.args$mkt$betas$comp <- 0
sim_data <- sim_mixed_dag(dag = g, f.args, N = 10000)
sim_data %>% ggplot(aes(mkt, sales)) + geom_boxplot() + stat_smooth() + coord_cartesian(ylim = c(-50, 50))
library(carData)
data("GSSvocab")
GSSvocab <- GSSvocab %>% filter(complete.cases(.))
g <- dagitty("dag {
ageGroup [pos=\"0,0\"]
vocab [pos=\"1,-1\"]
nativeBorn [pos=\"2,-2\"]
educ [pos=\"3,-1\"]
gender [pos=\"4,0\"]
nativeBorn -> educ
nativeBorn -> vocab
educ -> vocab
gender -> educ
ageGroup -> vocab
}")
tidy_dag <- tidy_dagitty(g)
tidy_dag$data$xend[1] <- 0.92; tidy_dag$data$yend[1] <- -0.96
tidy_dag$data$xend[2] <- 1.09
tidy_dag$data$xend[3] <- 3.08; tidy_dag$data$yend[3] <- -0.96
tidy_dag$data$xend[4] <- 2.92; tidy_dag$data$yend[4] <- -1.04
tidy_dag$data$xend[5] <- 1.07; tidy_dag$data$yend[5] <- -1.04
ggdag(tidy_dag, node_size = 28) + theme_dag_blank()
source("../miscellaneous files/fit_gam.R")
gam_fits <- fit_gam(dag = g, data = GSSvocab)
source("../miscellaneous files/sim_mixed_dag_gam_fits.R")
sim_data <- sim_mixed_dag_gam_fits(dag = g, gam_fits = gam_fits, N = nrow(GSSvocab))
bind_rows(GSSvocab %>% mutate(data = "Original"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(nativeBorn, vocab)) + geom_boxplot() + facet_wrap(~data)
bind_rows(GSSvocab %>% mutate(data = "Original"), sim_data %>% mutate(data = "Simulated")) %>%
ggplot(aes(educ, vocab)) + geom_point(alpha = 0.02) + facet_wrap(~data) + stat_smooth()
GSSvocab %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Original data")
sim_data %>% group_by(nativeBorn, gender) %>% summarise(freq = n()/nrow(.)) %>% spread(key = gender, value = freq) %>% pandoc.table(caption = "Simulated data")
